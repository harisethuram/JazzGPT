{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13179,
     "status": "ok",
     "timestamp": 1685874101954,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "k219Vg0K7uaD",
    "outputId": "4ab52b64-4a7b-4b3c-eceb-c8b0ac86e550"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#FOLDERNAME = './attempt2-main'\n",
    "#assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "#import sys\n",
    "#sys.path.append(f'/content/drive/My Drive/{FOLDERNAME}')\n",
    "#%cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5382,
     "status": "ok",
     "timestamp": 1685874107334,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "l1srJW9M7FYG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/home/markpock/venvs/jupyter-notebook/lib64/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing altrepalt.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "\n",
    "from generatemidi import generate_midi\n",
    "from model import Seq2SeqTransformer, JazzDataset, PositionalEncoding, TokenEmbedding\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "from torch import multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1685874107335,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "nNGopfVm7FYJ"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1685874155751,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "HmGPLwW3fngZ"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == pad_idx_har)\n",
    "    tgt_padding_mask = (tgt == pad_idx_mel)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8645,
     "status": "ok",
     "timestamp": 1685874116169,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "vHV2TQrV7FYK",
    "outputId": "87b4f30c-dcd4-4316-cc26-79e37fb2111e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In uncompressed mode\n",
      "loading data\n"
     ]
    }
   ],
   "source": [
    "# dress the data\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "dataset = JazzDataset()\n",
    "\n",
    "# Determine the size of the training set (e.g., 80% of the data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "# Determine the size of the validation set (e.g., 20% of the data)\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "# Split the DataLoader into training and validation sets\n",
    "train, val = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_data = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_data = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(dataset.har_to_i) + 1\n",
    "TGT_VOCAB_SIZE = len(dataset.mel_to_i) + 1\n",
    "EMB_SIZE = 128\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "PAD_IDX = 1\n",
    "\n",
    "\n",
    "pad_idx_har = dataset.har_to_i['end']\n",
    "pad_idx_mel = dataset.mel_to_i[tuple(np.array([0,0]))]\n",
    "start_idx_har = dataset.har_to_i['start']\n",
    "start_idx_mel = dataset.mel_to_i[tuple(np.array([200.,0.]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1685877542977,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "9s5tIgphf0-7",
    "outputId": "efc5d521-b286-4d1b-9a00-cb348410d8e2"
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184015,
     "status": "ok",
     "timestamp": 1685874399967,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "8VRCyaFs7FYL",
    "outputId": "f7b25fc5-ba4e-40fe-fbe4-94256e82803d"
   },
   "outputs": [],
   "source": [
    "# # training\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "# num_epochs = 100\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# print(f'Epoch 0 / {num_epochs}')\n",
    "# l = len(train_data)\n",
    "# for epoch in range(num_epochs):\n",
    "#     losses = None\n",
    "#     for i, batch in enumerate(train_data):\n",
    "#         if i % 500 == 0 : print(f'E{epoch} Batch {i} / {l}')\n",
    "#         optimizer.zero_grad()\n",
    "#         harmony = batch['harmony'].to(device)\n",
    "#         melody = batch['melody'].to(device)\n",
    "#         melody_in = melody[:, :-1]\n",
    "\n",
    "#         harmony_mask, melody_mask, harmony_padding_mask, melody_padding_mask = create_mask(harmony, melody_in)\n",
    "\n",
    "#         logits = model(src=harmony, trg=melody_in, src_mask=harmony_mask, \n",
    "#                         tgt_mask=melody_mask, src_padding_mask=harmony_padding_mask,\n",
    "#                         tgt_padding_mask=melody_padding_mask, memory_key_padding_mask=harmony_padding_mask)\n",
    "#         optimizer.zero_grad()\n",
    "#         melody_out = melody[:, 1:]\n",
    "#         inp, tar = logits.reshape(-1, logits.shape[-1]), melody_out.reshape(-1)\n",
    "       \n",
    "\n",
    "#         loss = loss_fn(input=inp, target=tar)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if i % 500 == 0 : print('loss: ', loss)\n",
    "#         losses = loss\n",
    "#     print(f'Epoch {epoch + 1} / {num_epochs}:\\nLoss ↦ {loss}')\n",
    "#     if ((epoch + 1) % 10) == 0:\n",
    "#         print(f'Dumping modell at epoch {epoch + 1}')\n",
    "#         with open(f'model_uncompressed_{epoch + 1}epochs.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_uncompressed_60epochs.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(raw):\n",
    "    # Got this off the interwebs. Works with numpy.\n",
    "    # Eventual type of sequences is\n",
    "    # list[list[float] (of length k, here 1), float]\n",
    "    # I want dependent typing.\n",
    "    \n",
    "    data = softmax(raw, dim=-1).to('cpu').detach().numpy()\n",
    "    sequences = [[list(), 0.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score - np.log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select k best\n",
    "        sequences = ordered[0]\n",
    "    return sequences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greed(raw):\n",
    "    '''\n",
    "    Greedily takes the argmax over the raw probabilities.\n",
    "    '''\n",
    "    return torch.max(raw, dim=1)[1].item()\n",
    "\n",
    "SIMPLE = [beam_search, greed]\n",
    "\n",
    "def sample(raw):\n",
    "    '''\n",
    "    Applies softmax over the raw probabilities, then uses it\n",
    "    to sample from a probability distribution.\n",
    "    '''\n",
    "    return multinomial(softmax(raw, dim=-1), 1).item()\n",
    "\n",
    "\n",
    "def relu(raw):\n",
    "    '''\n",
    "    Applies relu, then samples.\n",
    "    '''\n",
    "    return sample(nn.functional.relu(raw))\n",
    "\n",
    "def leaky(raw):\n",
    "    '''\n",
    "    Applies leaky relu, then samples.\n",
    "    '''\n",
    "    return sample(nn.functional.leaky_relu(raw, 0.1))\n",
    "\n",
    "def leaky2(raw):\n",
    "    '''\n",
    "    Applies leaky relu, then samples.\n",
    "    '''\n",
    "    return sample(nn.functional.leaky_relu(raw, 0.5))\n",
    "\n",
    "LINEAR = [sample, relu, leaky, leaky2]\n",
    "\n",
    "# The idea below is to sharpen the probabilities the slightest bit\n",
    "# to get more consistency. First we have x sqrt(x), which is a\n",
    "# little too repetitive and rhythmically constrained, then we have\n",
    "# x ln(x), which is asymptotically lower and should prove to possibly\n",
    "# work out a touch better...\n",
    "\n",
    "def xsqrtx(raw):\n",
    "    return sample(raw * torch.sqrt(nn.functional.relu(raw)))\n",
    "\n",
    "def xlnx(raw):\n",
    "    # Needs the extra relu bc log can sometimes be negative?\n",
    "    return sample(raw * torch.log(nn.functional.relu(raw) + 1))\n",
    "\n",
    "def exp(raw):\n",
    "    # This may be stupid. Scratch that, it probably is. When in\n",
    "    # doubt, try? Heh.\n",
    "    return sample(torch.exp(raw))\n",
    "\n",
    "def exp(raw):\n",
    "    return sample(raw * raw)\n",
    "\n",
    "SHARPEN = [xsqrtx, xlnx, exp]\n",
    "\n",
    "def tanh(raw):\n",
    "    return sample(torch.tanh(raw))\n",
    "\n",
    "def sigmoid(raw):\n",
    "    return sample(torch.sigmoid(raw))\n",
    "\n",
    "def cuberoot(raw):\n",
    "    # Must be declared piecewise to support negative numbers\n",
    "    relued = nn.functional.relu(raw)\n",
    "    pos = torch.pow(relued, 1/3)\n",
    "    neg = torch.pow(relued - raw, 1/3)\n",
    "    return sample(pos - neg)\n",
    "\n",
    "SMOOTH = [tanh, sigmoid, cuberoot]\n",
    "\n",
    "def xsqrtx_tanh(raw):\n",
    "    relued = nn.functional.relu(raw)\n",
    "    pos = raw * torch.sqrt(relued)\n",
    "    neg = torch.tanh(relued - raw)\n",
    "    return sample(pos - neg)\n",
    "\n",
    "def xsqrtx_cbrt(raw):\n",
    "    relued = nn.functional.relu(raw)\n",
    "    pos = raw * torch.sqrt(relued)\n",
    "    neg = torch.pow(relued - raw, 1/3)\n",
    "    return sample(pos - neg)\n",
    "\n",
    "PIECEWISE = [xsqrtx_tanh, xsqrtx_cbrt]\n",
    "\n",
    "# In the vein of sharpening the probabilities, we now explore\n",
    "# a slightly greedier approach using top-k sorting.\n",
    "# Three variations follow:\n",
    "# - Apply softmax to the top-k values, zeroing out all other\n",
    "#   probabilities.\n",
    "# - Apply top-k and zero out all other raw values, then take\n",
    "#   softmax.\n",
    "# - Uniformly choose from among the top-k indices.\n",
    "\n",
    "# We must also account for precisely how much of the data\n",
    "# we wish to choose. We start arbitrarily by using the top\n",
    "# tenth of the probabilities, about 60 words.\n",
    "\n",
    "def harsh_topk(raw):\n",
    "    K = int(raw.shape[1]) // 10\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    zeros = torch.zeros_like(raw)\n",
    "    zeros[:, indices[0]] = softmax(values, dim=-1)\n",
    "    return multinomial(zeros, 1).item()\n",
    "\n",
    "def lenient_topk(raw):\n",
    "    K = int(raw.shape[1]) // 10\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    zeros = torch.zeros_like(raw)\n",
    "    zeros[:, indices[0]] = values\n",
    "    return multinomial(softmax(zeros, dim=-1), 1).item()\n",
    "\n",
    "TOPK = [harsh_topk, lenient_topk]\n",
    "\n",
    "# Will probably want to pare K to be lower in here\n",
    "def uniform_topk(raw, K):\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    index = torch.randint(0, indices.shape[1], (1,)).item()\n",
    "    return indices[0, index]\n",
    "\n",
    "def uniform_topk10(raw):\n",
    "    # 1 tenth\n",
    "    return uniform_topk(raw, int(raw.shape[1]) // 10)\n",
    "\n",
    "def uniform_topk20(raw):\n",
    "    # 1 20th\n",
    "    return uniform_topk(raw, int(raw.shape[1]) // 20)\n",
    "\n",
    "def uniform_topk30(raw):\n",
    "    # 1 30th\n",
    "    return uniform_topk(raw, int(raw.shape[1]) // 30)\n",
    "\n",
    "def uniform_topk40(raw):\n",
    "    # 1 30th\n",
    "    return uniform_topk(raw, int(raw.shape[1]) // 40)\n",
    "\n",
    "def uniform_topk50(raw):\n",
    "    # 1 30th\n",
    "    return uniform_topk(raw, int(raw.shape[1]) // 40)\n",
    "\n",
    "UNIFORM = [uniform_topk10, uniform_topk20, uniform_topk30, uniform_topk40, uniform_topk50]\n",
    "\n",
    "\n",
    "def xsqrtx_topk(raw):\n",
    "    K = int(raw.shape[1]) // 20\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    \n",
    "    applied = values * torch.sqrt(nn.functional.relu(values))\n",
    "    \n",
    "    softmaxed = softmax(applied, dim=-1)\n",
    "    index = multinomial(softmaxed, 1).item()\n",
    "    return indices[0, index]\n",
    "\n",
    "def xlnx_topk(raw):\n",
    "    K = int(raw.shape[1]) // 20\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "\n",
    "    \n",
    "    applied = values * torch.log(nn.functional.relu(values) + 1)\n",
    "    \n",
    "    softmaxed = softmax(applied, dim=-1)\n",
    "    index = multinomial(softmaxed, 1).item()\n",
    "    return indices[0, index]\n",
    "                      \n",
    "def tanh_topk(raw):\n",
    "    K = int(raw.shape[1]) // 20\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    \n",
    "    applied = torch.tanh(values)\n",
    "    \n",
    "    softmaxed = softmax(applied, dim=-1)\n",
    "    index = multinomial(softmaxed, 1).item()\n",
    "    return indices[0, index]\n",
    "\n",
    "def sigmoid_topk(raw):\n",
    "    K = int(raw.shape[1]) // 20\n",
    "    values, indices = torch.topk(raw, K, dim=-1)\n",
    "    \n",
    "    applied = torch.sigmoid(values)\n",
    "    \n",
    "    softmaxed = softmax(applied, dim=-1)\n",
    "    index = multinomial(softmaxed, 1).item()\n",
    "    return indices[0, index]\n",
    "\n",
    "APPLIED = [xsqrtx_topk, xlnx_topk, tanh_topk, sigmoid_topk]\n",
    "\n",
    "FUNCTIONS = SIMPLE + LINEAR + SHARPEN + SMOOTH + PIECEWISE + TOPK + UNIFORM + APPLIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1685877697414,
     "user": {
      "displayName": "Hari Sethuraman",
      "userId": "10656769602959397051"
     },
     "user_tz": 420
    },
    "id": "Gfkd37QH7FYM"
   },
   "outputs": [],
   "source": [
    "# function to generate output sequence using a provided algorithm\n",
    "# for the next word\n",
    "\n",
    "def decode(model, src, src_mask, max_len, start_symbol, nextword=greed):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_mask).to(device)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n",
    "                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "\n",
    "        prob = model.generator(out[:, -1, :])\n",
    "        \n",
    "        next_word = nextword(prob)\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == pad_idx_mel or next_word == start_idx_mel:\n",
    "            print('END REACHED')\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str, func):\n",
    "    model.eval()\n",
    "    src = src_sentence\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=start_idx_mel, nextword=func).flatten()\n",
    "    return tgt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = lambda fns: {f.__name__ : f for f in fns}\n",
    "\n",
    "def indiv(harmony, func, filename='test', name='greed'):\n",
    "    out = translate(model, harmony.to(device).unsqueeze(dim=0), func)\n",
    "    length = out.shape[0]\n",
    "\n",
    "    inferred = np.zeros((length, 2))\n",
    "    for i in range(length):\n",
    "        #if (int(out[i])) == pad_idx_mel or\\\n",
    "        #    (int(out[i])) == start_idx_mel: break\n",
    "        inferred[i] = dataset.i_to_mel[int(out[i])]\n",
    "    generate_midi(inferred[:-1], f'{filename}_model_{name}')\n",
    "\n",
    "def workflow(batch, filename='test', gt=False, functions=FUNCTIONS):\n",
    "    melody, harmony = batch['melody'], batch['harmony']\n",
    "    \n",
    "    for name, func in fnames(functions).items():\n",
    "        print(name)\n",
    "        indiv(harmony, func, filename, name)\n",
    "    \n",
    "    if not gt: return\n",
    "    \n",
    "    gt = np.zeros((melody.shape[0], 2))\n",
    "    for i in range(1, melody.shape[0] - 2):\n",
    "        res = int(melody[i - 1].item())\n",
    "        breaker = int(melody[i].item())\n",
    "        if (breaker == start_idx_mel or\n",
    "            breaker == pad_idx_mel):\n",
    "            break\n",
    "        gt[i] = dataset.i_to_mel[res]\n",
    "\n",
    "    generate_midi(gt[1:-1, :], f'{filename}_gt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_topk10\n",
      "uniform_topk20\n",
      "END REACHED\n",
      "uniform_topk30\n",
      "uniform_topk40\n",
      "uniform_topk50\n",
      "xsqrtx_topk\n",
      "xlnx_topk\n",
      "tanh_topk\n",
      "END REACHED\n",
      "sigmoid_topk\n"
     ]
    }
   ],
   "source": [
    "workflow(val[0], filename='./topk/60epochs', gt=True,\n",
    "        functions=UNIFORM + APPLIED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCHANGES    = np.array([\"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", # A1\n",
    "                        \"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", \n",
    "                        \"F-7\", \"F-7\", \"Bb7\", \"Bb7\", \"Ebj7\", \"Ebj7\", \"Ab7\", \"Ab7\", \n",
    "                        \"D-7\", \"D-7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\",\n",
    "                        \"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", # A2\n",
    "                        \"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", \n",
    "                        \"F-7\", \"F-7\", \"Bb7\", \"Bb7\", \"Ebj7\", \"Ebj7\", \"Ab7\", \"Ab7\", \n",
    "                        \"D-7\", \"D-7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\",\n",
    "                        \"D7\", \"D7\", \"D7\", \"D7\", \"D7\", \"D7\", \"D7\", \"D7\", # B\n",
    "                        \"G7\", \"G7\", \"G7\", \"G7\", \"G7\", \"G7\", \"G7\", \"G7\", \n",
    "                        \"C7\", \"C7\", \"C7\", \"C7\", \"C7\", \"C7\", \"C7\", \"C7\", \n",
    "                        \"F7\", \"F7\", \"F7\", \"F7\", \"F7\", \"F7\", \"F7\", \"F7\",\n",
    "                        \"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", # A3\n",
    "                        \"Bbj7\", \"Bbj7\", \"G7\", \"G7\", \"C-7\", \"C-7\", \"F7\", \"F7\", \n",
    "                        \"F-7\", \"F-7\", \"Bb7\", \"Bb7\", \"Ebj7\", \"Ebj7\", \"Ab7\", \"Ab7\", \n",
    "                        \"C-7\", \"C-7\", \"F7\", \"F7\", \"Bbj7\", \"Bbj7\", \"Bbj7\", \"Bbj7\"\n",
    "                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inside_outside_metric_rc(notes, start_offset=0, chorus_count=1):\n",
    "    \"\"\"\n",
    "    - harmony: (l, 1) \n",
    "    - notes: (l2, 2)\n",
    "    - returns inside_outside_metric for rhythm changes in Bb\n",
    "    \"\"\"\n",
    "    harmony = RCHANGES\n",
    "    song_length = 128\n",
    "    harmony = np.tile(harmony, 4)\n",
    "    # print(notes.shape)\n",
    "    onsets = np.floor(np.roll(np.cumsum(notes[:, 1]), shift=1))# beats in which notes begin\n",
    "    \n",
    "    onsets[0] = 0\n",
    "    # print(\"N\", notes[:20, :])\n",
    "    # print(onsets[:20])\n",
    "    befores = np.where(onsets < start_offset)\n",
    "    onsets = np.delete(onsets, befores) - start_offset\n",
    "    if np.array([befores]).size > 0:\n",
    "        notes = notes[np.max(befores)+1:, :]\n",
    "    # notes = np.delete(notes, befores)\n",
    "    # onsets = onsets[i:] #- start_offset\n",
    "    extras = np.where(onsets >= song_length * chorus_count)\n",
    "    # print(\"e\", notes[extras, :])\n",
    "    # print(onsets[extras])\n",
    "    onsets = np.delete(onsets, extras)\n",
    "    #print(notes[:10])\n",
    "    #print(onsets[:10])\n",
    "    #print(onsets[:10])\n",
    "    notes[:, 1] = notes[:, 1]\n",
    "    chord_profiles = {\n",
    "        \"Bbj7\": [38, 41, 45, 46, 50, 53, 57, 58, 62, 65, 69, 70, 74, 77, 81, 82, 86, 89, 93, 94],\n",
    "        \"G7\": [38, 50, 62, 74, 86, 41, 53, 65, 77, 89, 43, 55, 67, 79, 91, 47, 59, 71, 83, 95], \n",
    "        \"C-7\": [36, 48, 60, 72, 84, 96, 39, 51, 63, 75, 87, 43, 55, 67, 79, 91, 46, 58, 70, 82, 94], #CEbGBb\n",
    "        \"F7\": [41, 53, 65, 77, 89, 45, 57, 69, 81, 93, 39, 51, 63, 75, 87, 36, 48, 60, 72, 84, 96], # FAEbC\n",
    "        \"F-7\": [41, 53, 65, 77, 89, 44, 56, 68, 80, 92, 39, 51, 63, 75, 87, 36, 48, 60, 72, 84, 96],\n",
    "        \"Bb7\": [38, 41, 44, 46, 50, 53, 56, 58, 62, 65, 68, 70, 74, 77, 80, 82, 86, 89, 92, 94],\n",
    "        \"Ebj7\": [38, 50, 62, 74, 86, 39, 51, 63, 75, 87, 43, 55, 67, 79, 91, 46, 58, 70, 82, 94], #DEbGBb\n",
    "        \"Ab7\": [44, 56, 68, 80, 92, 39, 51, 63, 75, 87, 36, 48, 60, 72, 84, 96, 42, 54, 66, 78, 90],\n",
    "        \"D-7\": [41, 53, 65, 77, 89, 45, 57, 69, 81, 93, 38, 50, 62, 74, 86, 36, 48, 60, 72, 84, 96], # FADC\n",
    "        \"D7\": [42, 54, 66, 78, 90, 46, 58, 70, 82, 94, 38, 50, 62, 74, 86, 36, 48, 60, 72, 84, 96], \n",
    "        \"C7\": [36, 48, 60, 72, 84, 96, 40, 52, 64, 76, 88, 43, 55, 67, 79, 91, 46, 58, 70, 82, 94], \n",
    "    }\n",
    "    num_outside = 0\n",
    "    num_inside = 0\n",
    "    cur_beat = 0\n",
    "    # i = 0\n",
    "    # while cur_beat < 128+start_offset:\n",
    "    #     if notes[i, 0] == 0 or start_offset > cur_beat:\n",
    "    #         print(\"zero\", cur_beat, notes[i, 0], notes[i, 1])\n",
    "    #         cur_beat += notes[i, 1]\n",
    "    #         i += 1\n",
    "    #         continue\n",
    "    #     curr_chord = harmony[math.floor(cur_beat) - start_offset]\n",
    "    #     curr_note = notes[i, 0]\n",
    "    #     good_notes = chord_profiles[curr_chord]\n",
    "    #     if curr_note in good_notes:\n",
    "    #         print(\"YES\", curr_note, curr_chord, cur_beat)\n",
    "    #         num_inside += 1\n",
    "    #     else:\n",
    "    #         print(\"NO\", curr_note, curr_chord, cur_beat)\n",
    "    #     cur_beat += notes[i, 1]\n",
    "        # i += 1\n",
    "        \n",
    "        \n",
    "    # print(harmony.shape)\n",
    "    #print(np.max(onsets))\n",
    "    for i in range(onsets.shape[0]):\n",
    "        if notes[i, 0] == 0:\n",
    "            continue\n",
    "        curr_chord = harmony[int(onsets[i])]\n",
    "        # print(onsets[i])\n",
    "        good_notes = chord_profiles[curr_chord]\n",
    "        curr_pitch = int(notes[i, 0])\n",
    "        # print(curr_chord, curr_pitch, onsets[i] % 4, np.floor(onsets[i]/4))\n",
    "        if curr_pitch in good_notes:\n",
    "            #print(\"YES\", curr_pitch, curr_chord, onsets[i])\n",
    "            num_inside += 1\n",
    "        else:\n",
    "            #print(\"NO\", curr_pitch, curr_chord, onsets[i])\n",
    "            num_outside += 1\n",
    "\n",
    "    return num_inside / notes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([721, 217, 217, 633, 633, 254, 254, 573, 573, 217, 217, 633, 633, 254,\n",
       "        254, 573, 573, 554, 554, 201, 201, 517, 517,  81,  81, 314, 314, 633,\n",
       "        633, 254, 254, 573, 573, 217, 217, 633, 633, 254, 254, 573, 573, 217,\n",
       "        217, 633, 633, 254, 254, 573, 573, 554, 554, 201, 201, 517, 517,  81,\n",
       "         81, 314, 314, 633, 633, 254, 254, 573, 573, 333, 333, 333, 333, 333,\n",
       "        333, 333, 333, 633, 633, 633, 633, 633, 633, 633, 633, 273, 273, 273,\n",
       "        273, 273, 273, 273, 273, 573, 573, 573, 573, 573, 573, 573, 573, 217,\n",
       "        217, 633, 633, 254, 254, 573, 573, 217, 217, 633, 633, 254, 254, 573,\n",
       "        573, 554, 554, 201, 201, 517, 517,  81,  81, 254, 254, 573, 573, 217,\n",
       "        217, 217, 217, 723])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harm = [dataset.har_to_i[chord] for chord in (['start'] + list(RCHANGES) + ['end'])]\n",
    "harm = torch.tensor(harm)\n",
    "harm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_indiv(harmony, func):\n",
    "    out = translate(model, harmony.to(device).unsqueeze(dim=0), func)\n",
    "    length = out.shape[0]\n",
    "\n",
    "    inferred = np.zeros((length, 2))\n",
    "    for i in range(length):\n",
    "        inferred[i] = dataset.i_to_mel[int(out[i])]\n",
    "    \n",
    "    return inside_outside_metric_rc(inferred)\n",
    "\n",
    "def evalflow(harmony, functions=FUNCTIONS):\n",
    "    metric = {}\n",
    "    for name, func in fnames(functions).items():\n",
    "        metric[name] = []\n",
    "        for _ in range(10):\n",
    "            num = eval_indiv(harmony, func)\n",
    "            metric[name].append(num)\n",
    "        #print(f'{name} ↦ {sum(metric[name]) / len(metric[name]):.3f}')\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indiv(harmony, func):\n",
    "    out = translate(model, harmony.to(device).unsqueeze(dim=0), func)\n",
    "    length = out.shape[0]\n",
    "\n",
    "    inferred = np.zeros((length, 2))\n",
    "    for i in range(length):\n",
    "        inferred[i] = dataset.i_to_mel[int(out[i])]\n",
    "    \n",
    "    generate_midi(inferred[1:-1], 'inferred')\n",
    "\n",
    "gen_indiv(harm, lenient_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_search ↦ 0.230\n",
      "greed ↦ 0.230\n",
      "sample ↦ 0.216\n",
      "relu ↦ 0.184\n",
      "leaky ↦ 0.230\n",
      "leaky2 ↦ 0.210\n",
      "xsqrtx ↦ 0.256\n",
      "xlnx ↦ 0.241\n",
      "exp ↦ 0.007\n",
      "END REACHED\n",
      "tanh ↦ 0.124\n",
      "sigmoid ↦ 0.096\n",
      "END REACHED\n",
      "cuberoot ↦ 0.205\n",
      "xsqrtx_tanh ↦ 0.253\n",
      "xsqrtx_cbrt ↦ 0.256\n",
      "harsh_topk ↦ 0.217\n",
      "lenient_topk ↦ 0.153\n",
      "uniform_topk10 ↦ 0.274\n",
      "uniform_topk20 ↦ 0.283\n",
      "uniform_topk30 ↦ 0.279\n",
      "uniform_topk40 ↦ 0.292\n",
      "uniform_topk50 ↦ 0.288\n",
      "xsqrtx_topk ↦ 0.244\n",
      "xlnx_topk ↦ 0.229\n",
      "tanh_topk ↦ 0.279\n",
      "sigmoid_topk ↦ 0.295\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d4de01870186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mharm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} ↦ {sum(metric[name]) / len(metric[name]):.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "end = evalflow(harm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_search ↦ 0.2296\n",
      "greed ↦ 0.2296\n",
      "sample ↦ 0.2163\n",
      "relu ↦ 0.1844\n",
      "leaky ↦ 0.2296\n",
      "leaky2 ↦ 0.2104\n",
      "xsqrtx ↦ 0.2563\n",
      "xlnx ↦ 0.2407\n",
      "exp ↦ 0.0074\n",
      "tanh ↦ 0.1239\n",
      "sigmoid ↦ 0.0963\n",
      "cuberoot ↦ 0.2047\n",
      "xsqrtx_tanh ↦ 0.2526\n",
      "xsqrtx_cbrt ↦ 0.2563\n",
      "harsh_topk ↦ 0.2170\n",
      "lenient_topk ↦ 0.1526\n",
      "uniform_topk10 ↦ 0.2741\n",
      "uniform_topk20 ↦ 0.2830\n",
      "uniform_topk30 ↦ 0.2793\n",
      "uniform_topk40 ↦ 0.2919\n",
      "uniform_topk50 ↦ 0.2881\n",
      "xsqrtx_topk ↦ 0.2437\n",
      "xlnx_topk ↦ 0.2289\n",
      "tanh_topk ↦ 0.2793\n",
      "sigmoid_topk ↦ 0.2948\n"
     ]
    }
   ],
   "source": [
    "for name in end:\n",
    "    print(f'{name} ↦ {sum(end[name]) / len(end[name]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "19F7fPV7LVKVRrOPr3DfR7wSYk1hm3FFw",
     "timestamp": 1685848495410
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
